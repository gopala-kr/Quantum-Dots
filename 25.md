- [2 OLMo 2 Furious](https://arxiv.org/pdf/2501.00656)
- [1.58-bit FLUX](https://www.arxiv.org/pdf/2412.18653)
- [Memory Layers at Scale](https://arxiv.org/pdf/2412.09764)
- [Agents Are Not Enough](https://arxiv.org/html/2412.16241v1)
- [Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs](https://arxiv.org/pdf/2412.21187)
- [IsarStep: a Benchmark for High-level Mathematical Reasoning](https://arxiv.org/pdf/2006.09265)
- [DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought](https://arxiv.org/pdf/2412.17498)
- [LearnLM: Improving Gemini for Learning](https://www.arxiv.org/pdf/2412.16429)
- [DeepSeek-V3 Technical Report](https://arxiv.org/pdf/2412.19437)
- [Large Concept Models: Language Modeling in a Sentence Representation Space](https://arxiv.org/pdf/2412.08821)
- [Explore Theory of Mind: Program-guided adversarial data generation for theory of mind reasoning](https://arxiv.org/pdf/2412.12175)
- [Reinforcement Learning: An Overview](https://arxiv.org/pdf/2412.05265)
- [GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations](https://arxiv.org/pdf/1907.13052)
- [AutoFeedback: An LLM-based Framework for Efficient and Accurate API Request Generation](https://arxiv.org/pdf/2410.06943)
- [TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks](https://arxiv.org/pdf/2412.14161)
- [Alignment faking in large language models](https://arxiv.org/pdf/2412.14093)
- [Qwen2.5 Technical Report](https://arxiv.org/pdf/2412.15115)
- [Precise Length Control in Large Language Models](https://arxiv.org/pdf/2412.11937)
